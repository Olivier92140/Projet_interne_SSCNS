---
title: "Modèles de mélange de gaussiennes"
author: "Olivier Malahel"
format: html
from: markdown+emoji
code-block-bg: true
code-block-border-left: "#31BAE9"
---

## Introduction

Dans cet exemple, nous ajustons un **modèle de mélange de lois normales** à des données simulées, en utilisant le package R `mclust`. Le but est d’identifier automatiquement des groupes (ou classes) au sein des données.

## Préambule : Simulation des données 

On simule 200 points selon des 2 lois normales

```{r}
#| message: false
#| warning: false
# chargement des packages
if (!requireNamespace("mclust", quietly = TRUE)) {
  install.packages("mclust")
}
library(mclust)
set.seed(123)

# Deux populations gaussiennes
x1 <- rnorm(100, mean = 0, sd = 1)
x2 <- rnorm(100, mean = 5, sd = 1.5)

# Données mélangées
x <- c(x1, x2)
```

## 1. Fonction de densité du mélange
```{r}

# Densité d’un mélange à 2 composantes
densite_melange <- function(x, pi, mu, sigma) {
  pi[1] * dnorm(x, mean = mu[1], sd = sigma[1]) +
  pi[2] * dnorm(x, mean = mu[2], sd = sigma[2])
}
```

## 2. Données complètes
```{r}
# Construction de Z complet (connu car simulation)
z <- c(rep(1, 100), rep(2, 100))

# Log-vraisemblance complète
log_vraisemblance_completee <- function(x, z, pi, mu, sigma) {
  sum(log(pi[z]) + dnorm(x, mean = mu[z], sd = sigma[z], log = TRUE))
}

```

## 3. Estimation par EM via mclust

```{r}
# Estimation avec mclust
res <- Mclust(x, G = 2)  # G = nombre de composantes

# Résumé des paramètres
summary(res)
```

<u>Conclusion</u> : Sur les 200 points simulés, 96 ont été assignés au cluster 1, et 104 au cluster 2, selon la règle du maximum a posteriori $t_{ik} = P(Z_n = k \mid X_n = x_n)$. 96 points sont tels que la probabilité a posteriori $t_{i1} > t_{i2}$ et 104 points sont tels que $t_{i1} < t_{i2}$ avec $t_{i1} + t_{i2} = 1$

## 4. Affichage de la densité estimée

```{r}
plot(res, what = "density", main = "Estimation du modèle de mélange par EM")
```

